# Conflict Prediction Models: ACLED, Amnesty International, and Human Rights Watch

This repository contains three trained predictive models for conflict prediction, each utilising different datasets to explore and critically analyse the intersection of Digital Humanities (DH), Security Studies, and AI. These models are part of a broader research project that investigates how predictive analytics in the humanitarian and security sectors should be developed and applied, with an emphasis on human-centered design and ethical implications.

Models

1. ACLED_ME (Middle East Conflict Model)

This model is trained on the ACLED (Armed Conflict Location & Event Data Project) dataset, specifically focusing on conflict data in the Middle East. The model aims to predict conflict events based on historical data, providing insights into patterns and potential escalation in the region.

2. Amnesty International Annual Reports Model

This model utilises Amnesty International’s annual reports from 2015-2025. The text-based model analyses qualitative data to predict the likelihood of human rights violations, highlighting trends in global human rights practices over the years.

3. Human Rights Watch Annual Reports Model

Trained on Human Rights Watch annual reports from 2015-2025, this model analyses the textual data from one of the most comprehensive sources of human rights violations across the globe. It aims to detect patterns in violations and predict potential areas of concern based on historical trends.

Purpose & Relevance

This research explores the role of Digital Humanities in the emerging field of AI and predictive analytics within the humanitarian sector. The rapid adoption of predictive models for conflict prediction by international organisations and NGOs necessitates a critical evaluation of these technologies’ design, ethics, and implications. Digital Humanities offers an interdisciplinary approach to address the socio-technical systems behind these models and helps ensure that human values are at the center of AI-driven technologies.

Through the analysis of the ACLED dataset, alongside qualitative reports from global NGOs, this research critically interrogates how data collection, categorisation, and structuring influence the narratives of conflict. It emphasises the importance of human-centered design in AI technologies and the potential ethical and epistemic biases embedded in predictive models.

This research draws on datasets from:
	•	ACLED (https://acleddata.com/data/)
	•	Amnesty International (https://www.amnesty.org/en/documents/pol10/5670/2023/en/)
	•	Human Rights Watch (https://www.hrw.org/publications)

